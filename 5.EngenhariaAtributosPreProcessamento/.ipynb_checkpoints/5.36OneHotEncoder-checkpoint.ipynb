{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e498b0",
   "metadata": {},
   "source": [
    "# Categorical Encoding com One Hot Encoding\n",
    "\n",
    "- técnica de pré-processamento de engenharia de dados\n",
    "- transformar atributo categórico em contínuo adicionando uma coluna ao ds para cada atributo\n",
    "1: ocorrência do atributo e 0: não ocorrência do atributo\n",
    "<br><br>\n",
    "- Requisitos no pyspark\n",
    "    -1. Atributo já deve estar como número, podemos usar StringIndexer para transformar. \n",
    "<br><br>   \n",
    "- Output no pyspark > matriz esparsa \n",
    "def. Uma matriz com muitos elementos nulos chama-se esparsa; caso contrário, é densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b467b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init() # inicializa interface pyspark jupyter\n",
    "spark = SparkSession.builder.appName(\"onehot\").getOrCreate()\n",
    "#inicializa sessão no spark com nome importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3968f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494b1f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure|Balance |NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|619        |France   |Female|42 |2     |0       |1            |1        |1             |10134888       |1     |\n",
      "|608        |Spain    |Female|41 |1     |8380786 |1            |0        |1             |11254258       |0     |\n",
      "|502        |France   |Female|42 |8     |1596608 |3            |1        |0             |11393157       |1     |\n",
      "|699        |France   |Female|39 |1     |0       |2            |0        |0             |9382663        |0     |\n",
      "|850        |Spain    |Female|43 |2     |12551082|1            |1        |1             |790841         |0     |\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = spark.read.load(\"Churn.csv\", format=\"csv\", sep=\";\", inferSchema=True, header = True)\n",
    "churn.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7c1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Cria os índices para \"Geography e \"Gender: (Requisito do one hot encoding)\n",
    "indice = StringIndexer(inputCol =\"Geography\" , outputCol =\"Indexer_c1\") #(instancia objeto indice)\n",
    "indiceonehot = indice.fit(churn).transform(churn)\n",
    "\n",
    "indice = StringIndexer(inputCol =\"Gender\" , outputCol =\"Indexer_c2\") #(instancia objeto indice)\n",
    "indiceonehot = indice.fit(indiceonehot).transform(indiceonehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a339e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Indexer_c1|Indexer_c2|\n",
      "+----------+----------+\n",
      "|       0.0|       1.0|\n",
      "|       2.0|       1.0|\n",
      "|       0.0|       1.0|\n",
      "|       0.0|       1.0|\n",
      "|       2.0|       1.0|\n",
      "|       2.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       1.0|       1.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       2.0|       0.0|\n",
      "|       0.0|       1.0|\n",
      "|       0.0|       1.0|\n",
      "|       2.0|       1.0|\n",
      "|       1.0|       0.0|\n",
      "|       1.0|       0.0|\n",
      "|       2.0|       1.0|\n",
      "|       2.0|       0.0|\n",
      "|       0.0|       1.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indiceonehot.select(\"Indexer_c1\", \"Indexer_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942e9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d43e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = OneHotEncoder(inputCols=[\"Indexer_c1\", \"Indexer_c2\"], outputCols=[\"onehot_c1\",\"one_hot_c2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a65912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|onehot_c1    |one_hot_c2   |\n",
      "+-------------+-------------+\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "|(2,[],[])    |(1,[],[])    |\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "|(2,[],[])    |(1,[],[])    |\n",
      "|(2,[],[])    |(1,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[1],[1.0])|(1,[],[])    |\n",
      "|(2,[0],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[],[])    |(1,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "|(2,[],[])    |(1,[],[])    |\n",
      "|(2,[1],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[1],[1.0])|(1,[0],[1.0])|\n",
      "|(2,[],[])    |(1,[],[])    |\n",
      "|(2,[],[])    |(1,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(1,[],[])    |\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = onehot.fit(indiceonehot)\n",
    "onehotout = modelo.transform(indiceonehot)\n",
    "onehotout.select(\"onehot_c1\",\"one_hot_c2\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
