{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a16e2f",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron:\n",
    "\n",
    "- conjunto de neurônios dispostos em camadas\n",
    "- para o MLP, todos os neurônios de uma camada estão conectados com todos os neurônios das \n",
    "camadas seguintes (full conected ou altamente conectado)\n",
    "- não existe conexão entre neurônios da mesma camada\n",
    "- dados percorrem da esquerda para a direita, funcionando através de ajuste de pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f640918",
   "metadata": {},
   "source": [
    "# Componentes e Mecanismo: \n",
    "- camada de entrada: terá um neurônio para cada atributo (variáveis independentes)\n",
    "- camada de saída: \n",
    "    * classificação multiclasse: um neurônio para cada classe (variável dependente) \n",
    "    * classificação binária (output \"1/0\"): 2 ou 1 neurônios na camada de saída (1 exclusivo\n",
    "    para cada classe, ou 1 que funciona para ambas classes (1 ou 0).\n",
    "    * regressão: 1 neurônio\n",
    "- camada oculta: apresentam os pesos e funções de ativação nas sinapses (as ligações dos neurônios)\n",
    "quando a rede inicia, são gerados aleatoriamente valores pequenos para os pesos. Função de perda (loss \n",
    "function) mede o erro associada a passagem dos registros pela rede, propagando este erro de volta para rede, \n",
    "(backpropagation) ajustando os pesos da rede. Assim, os pesos vão se ajustando e a rede vai aprendendo. \n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f7b70",
   "metadata": {},
   "source": [
    "# Hiper Parâmetros:\n",
    "- layers: camadas, é dado por um vetor contendo a qtd de neurônios em cada camada\n",
    "[camada de entrada, camadas ocultas, camada de saída¹]\n",
    "¹: em caso de classificação, tem a qtd de neurônios igual a de classes, para regressão, temos 1 neurônio de \n",
    "saída. \n",
    "- seed: semente,\n",
    "- stepSize: o quanto os pesos serão atualizados em cada iteração (learning rate) (deafult=0,03)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8210aa0",
   "metadata": {},
   "source": [
    "# Qual a melhor configuração de camada oculta?\n",
    "cálculo: (qtd_atributos + qtd_classes)/2 ~ qtd de neurônios na camada oculta (arred pra cima)\n",
    "    \n",
    "ex: cam entrada = 4, cam saída = 3 > 4+3/2 = 3,5 (4)\n",
    "    \n",
    "testando possíveis configurações:\n",
    "[4,4,4,3]\n",
    "[4,4,3,4,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396b8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"MLP\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d639539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
    "print(iris.count())\n",
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdf9f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+-----------------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|     independente|\n",
      "+-----------+----------+-----------+----------+-----------+-----------------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+-----------+----------+-----------+----------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criação mde vetor com variáveis independentes:\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "asb = VectorAssembler(inputCols=[\"sepallength\",\"sepalwidth\",\"petallength\",\"petalwidth\"], \n",
    "                      outputCol=\"independente\")\n",
    "irisas = asb.transform(iris)\n",
    "irisas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c24560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+-----------------+----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|     independente|dependente|\n",
      "+-----------+----------+-----------+----------+-----------+-----------------+----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "+-----------+----------+-----------+----------+-----------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StringIndexer para gerar indexação das classes:\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "ind = StringIndexer(inputCol=\"class\", outputCol=\"dependente\")\n",
    "irisas = ind.fit(irisas).transform(irisas)\n",
    "irisas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f141b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|          class|dependente|\n",
      "+---------------+----------+\n",
      "|    Iris-setosa|       0.0|\n",
      "| Iris-virginica|       2.0|\n",
      "|Iris-versicolor|       1.0|\n",
      "+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# observa classes distintos das colunas pra validar:\n",
    "irisas.select(\"class\",\"dependente\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450cd229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "irisTreino, irisTeste = irisas.randomSplit([0.7,0.3])\n",
    "print(irisTreino.count())\n",
    "print(irisTeste.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413404c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=10, layers=[4,5,4,3], featuresCol=\"independente\", \n",
    "                                     labelCol=\"dependente\")\n",
    "modelo = mlp.fit(irisTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50607757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|dependente|prediction|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       1.0|       2.0|\n",
      "|       1.0|       2.0|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previsao = modelo.transform(irisTeste) \n",
    "previsao.select(\"dependente\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e23d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "# Avaliando performance:\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "performance = MulticlassClassificationEvaluator(labelCol=\"dependente\", predictionCol=\"prediction\",\n",
    "                                               metricName=\"accuracy\")\n",
    "acuracia = performance.evaluate(previsao)\n",
    "print(acuracia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718ccd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxIter: 10\n",
      "Layers: [4, 5, 4, 3]\n",
      "StepSize: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Ajustando Hiper Parâmetros:\n",
    "\n",
    "print(\"MaxIter: \" + str(modelo.getMaxIter()))\n",
    "print(\"Layers: \" + str(modelo.getLayers()))\n",
    "print(\"StepSize: \" + str(modelo.getStepSize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e78d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando número máximo de iterações:\n",
    "parunico = {modelo.maxIter: 1000} # dicionário padrão chave-valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77f20be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp.fit(irisTreino, parunico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68027add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxIter: 1000\n",
      "Layers: [4, 5, 4, 3]\n",
      "StepSize: 0.03\n"
     ]
    }
   ],
   "source": [
    "print(\"MaxIter: \" + str(modelo.getMaxIter()))\n",
    "print(\"Layers: \" + str(modelo.getLayers()))\n",
    "print(\"StepSize: \" + str(modelo.getStepSize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f5157a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|dependente|prediction|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       1.0|       1.0|\n",
      "|       1.0|       1.0|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nova previsão: \n",
    "previsao = modelo.transform(irisTeste) \n",
    "previsao.select(\"dependente\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9cec793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534883720930233\n"
     ]
    }
   ],
   "source": [
    "# Avaliando performance: maxIter 10 > 1000 : acurácia: 61% > 95% \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "performance = MulticlassClassificationEvaluator(labelCol=\"dependente\", predictionCol=\"prediction\",\n",
    "                                               metricName=\"accuracy\")\n",
    "acuracia = performance.evaluate(previsao)\n",
    "print(acuracia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
